{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports:"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T20:51:46.133920Z","iopub.status.busy":"2024-03-21T20:51:46.133242Z","iopub.status.idle":"2024-03-21T20:51:53.233627Z","shell.execute_reply":"2024-03-21T20:51:53.232620Z","shell.execute_reply.started":"2024-03-21T20:51:46.133887Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","from tqdm import tqdm\n","import numpy as np\n","import torch\n","import torchvision\n","from torch import nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset\n","from torch.optim import lr_scheduler\n","from torchvision import transforms\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import pywt\n","\n","cuda = torch.cuda.is_available()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T20:51:53.236194Z","iopub.status.busy":"2024-03-21T20:51:53.235391Z","iopub.status.idle":"2024-03-21T20:52:30.977340Z","shell.execute_reply":"2024-03-21T20:52:30.976052Z","shell.execute_reply.started":"2024-03-21T20:51:53.236158Z"},"trusted":true},"outputs":[],"source":["class BlurDataset(Dataset):\n","    def __init__(self, images, labels, train=True, transform=None):\n","        \n","        self.train = train\n","        self.labels = labels\n","        self.images = images\n","        self.classes = list(set(labels)) \n","        self.transform = transform\n","        \n","    def __getitem__(self, index: int):\n","        img_path = self.images[index]\n","        label = self.labels[index]\n","        original = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","        transformed = self.transform(original).unsqueeze(0)\n","        return transformed, label\n","\n","    def __len__(self):\n","        return len(self.images)"]},{"cell_type":"markdown","metadata":{},"source":["# Transformada de Fourier:"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T02:25:40.427538Z","iopub.status.busy":"2024-03-21T02:25:40.426920Z","iopub.status.idle":"2024-03-21T02:25:40.442786Z","shell.execute_reply":"2024-03-21T02:25:40.441781Z","shell.execute_reply.started":"2024-03-21T02:25:40.427498Z"},"trusted":true},"outputs":[],"source":["def aplicar_janela_hann(imagem):\n","    linhas, colunas = imagem.shape[:2]\n","    hann_vertical = np.hanning(linhas) # Criar a janela de Hann\n","    hann_horizontal = np.hanning(colunas)\n","    janela_2d = hann_vertical[:, np.newaxis] * hann_horizontal # Aplicar a janela à imagem\n","    imagem_janelada = imagem * janela_2d # Multiplicar a imagem pela janela\n","    return imagem_janelada\n","\n","def aplicar_transformada_fourier(imagem):\n","    imagem = cv2.resize(imagem, dsize=(224, 224))\n","    imagem = aplicar_janela_hann(imagem)\n","    transformada_fourier = np.fft.fft2(imagem) # Calcular a transformada de Fourier 2D\n","    transformada_fourier_deslocada = np.fft.fftshift(transformada_fourier) # Mover o componente de baixa frequência para o centro\n","    espectro_magnitude = np.log(np.abs(transformada_fourier_deslocada) + 1) # Calcular o espectro de magnitude (log para melhor visualização)\n","    espectro_magnitude = cv2.resize(espectro_magnitude, dsize=(120, 120))\n","    return espectro_magnitude"]},{"cell_type":"markdown","metadata":{},"source":["# Transformada de Wavelets:"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T20:52:35.774979Z","iopub.status.busy":"2024-03-21T20:52:35.774561Z","iopub.status.idle":"2024-03-21T20:52:35.845568Z","shell.execute_reply":"2024-03-21T20:52:35.844642Z","shell.execute_reply.started":"2024-03-21T20:52:35.774943Z"},"trusted":true},"outputs":[],"source":["def aplicar_transformada_haar_merged(imagem):\n","    coeffs = pywt.wavedec2(imagem, 'haar', level=2)\n","    cA2, (cH2, cV2, cD2), (cH1, cV1, cD1) = coeffs\n","    imagem_reconstruida = pywt.waverec2(coeffs, 'haar')\n","    merged = cv2.add(cH2, cV2)\n","    merged = cv2.resize(merged, dsize=(120, 120))\n","    return merged"]},{"cell_type":"markdown","metadata":{},"source":["---\n","# Classifier:"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T20:52:45.797291Z","iopub.status.busy":"2024-03-21T20:52:45.796700Z","iopub.status.idle":"2024-03-21T20:52:45.808677Z","shell.execute_reply":"2024-03-21T20:52:45.807811Z","shell.execute_reply.started":"2024-03-21T20:52:45.797261Z"},"trusted":true},"outputs":[],"source":["class CNN(nn.Module):\n","\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.convnet = nn.Sequential(\n","            nn.Conv2d(1, 32, kernel_size=3,padding=1), nn.ReLU(),\n","            nn.Conv2d(32, 32, kernel_size=3,padding=1), nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","            \n","            nn.Conv2d(32, 64, kernel_size=3,padding=1), nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","            \n","            nn.Conv2d(64, 128, kernel_size=3,padding=1), nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","            \n","            nn.Flatten()\n","        )\n","        \n","        self.fc = nn.Sequential(\n","            nn.Linear(28800, 1024),\n","            nn.ReLU(),\n","            nn.Dropout(),\n","            nn.BatchNorm1d(1024),\n","            \n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Dropout(),\n","            nn.BatchNorm1d(512),\n","            \n","            nn.Linear(512, 3),\n","        )\n","\n","    def forward(self, x):\n","        x = self.convnet(x)\n","        x = self.fc(x)\n","        return x\n","\n","    def get_embedding(self, x):\n","        return self.forward(x)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T20:52:45.999350Z","iopub.status.busy":"2024-03-21T20:52:45.999072Z","iopub.status.idle":"2024-03-21T20:52:46.024825Z","shell.execute_reply":"2024-03-21T20:52:46.023917Z","shell.execute_reply.started":"2024-03-21T20:52:45.999326Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, RocCurveDisplay\n","\n","\n","def get_metrics(y_targets, y_preds, y_probs=None):\n","    acc = accuracy_score(y_targets, y_preds)\n","    prec = precision_score(y_targets, y_preds, average='macro', zero_division=0.0)\n","    rec = recall_score(y_targets, y_preds, average='macro', zero_division=0.0)\n","    if not y_probs == None:\n","        y_probs = np.array(y_probs)\n","        y_onehot_test = np.array([[int(tg.item()==0), int(tg.item()==1), int(tg.item()==2)] for tg in y_targets])\n","        micro_roc_auc_ovr = roc_auc_score(\n","            y_onehot_test,\n","            y_probs,\n","            multi_class=\"ovr\",\n","            average=\"micro\",\n","        )\n","        return acc, prec, rec, micro_roc_auc_ovr\n","    return acc, prec, rec, None\n","\n","\n","def fit(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, start_epoch=0):\n","    history = {'train_loss': [], 'train_acc': [], 'train_prec': [], 'train_rec': [],\n","              'val_loss': [], 'val_acc': [], 'val_prec': [], 'val_rec': []}\n","\n","    for epoch in range(start_epoch, n_epochs):\n","        epoch_str = \"[{} / {} epochs]\".format(epoch, n_epochs)\n","        \n","        train_loss, y_targets, y_preds = train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval, epoch_str)\n","        train_acc, train_prec, train_rec, _ = get_metrics(y_targets, y_preds)\n","        history['train_loss'].append(train_loss)\n","        history['train_acc'].append(train_acc)\n","        history['train_prec'].append(train_prec)\n","        history['train_rec'].append(train_rec)\n","        message = 'Epoch: {}/{}. train - avgloss: {:.4f} | acc: {:.4f} | precision: {:.4f} | recall: {:.4f} '.format(\n","            epoch + 1, n_epochs, train_loss, train_acc, train_prec, train_rec)\n","\n","        if not val_loader == None:\n","            val_loss, y_targets, y_preds, _ = test_epoch(val_loader, model, loss_fn, cuda)\n","            val_acc, val_prec, val_rec, _ = get_metrics(y_targets, y_preds)\n","            history['val_loss'].append(val_loss)\n","            history['val_acc'].append(val_acc)\n","            history['val_prec'].append(val_prec)\n","            history['val_rec'].append(val_rec)\n","            message += '\\nEpoch: {}/{}. valid - avgloss: {:.4f} | acc: {:.4f} | precision: {:.4f} | recall: {:.4f} '.format(\n","                epoch + 1, n_epochs, val_loss, val_acc, val_prec, val_rec)\n","            \n","        print(message)\n","        scheduler.step()\n","    return history\n","\n","         \n","def train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval, epoch_str):\n","    model.train()\n","    losses = []\n","    total_loss = 0\n","    \n","    y_preds = []\n","    y_targets = []\n","    \n","    pbar = tqdm(train_loader, desc=\"{} Training - avg_loss: \".format(epoch_str))\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        target = target if len(target) > 0 else None\n","        if not type(data) in (tuple, list):\n","            data = (data,)\n","        if cuda:\n","            data = tuple(d.cuda() for d in data)\n","            if target is not None:\n","                target = target.cuda()\n","\n","        optimizer.zero_grad()\n","        outputs = model(*data)\n","\n","        if type(outputs) not in (tuple, list):\n","            outputs = (outputs,)\n","\n","        loss_inputs = outputs\n","        if target is not None:\n","            target = (target,)\n","            loss_inputs += target\n","\n","        loss_outputs = loss_fn(*loss_inputs)\n","        loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n","        losses.append(loss.item())\n","        total_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        _, predicted = outputs[0].max(1)\n","        y_preds += predicted.cpu()\n","        y_targets += target[0].cpu()\n","        \n","        pbar.set_description(\"{} Training - avg_loss: {:.4f}\".format(epoch_str , np.mean(losses)))\n","\n","    total_loss /= (batch_idx + 1)\n","    return total_loss, y_targets, y_preds\n","\n","\n","def test_epoch(val_loader, model, loss_fn, cuda):\n","    with torch.no_grad():\n","        model.eval()\n","        val_loss = 0\n","        \n","        y_probs = []\n","        y_preds = []\n","        y_targets = []\n","        \n","        for batch_idx, (data, target) in enumerate(val_loader):\n","            target = target if len(target) > 0 else None\n","            if not type(data) in (tuple, list):\n","                data = (data,)\n","            if cuda:\n","                data = tuple(d.cuda() for d in data)\n","                if target is not None:\n","                    target = target.cuda()\n","\n","            outputs = model(*data)\n","\n","            if type(outputs) not in (tuple, list):\n","                outputs = (outputs,)\n","            loss_inputs = outputs\n","            if target is not None:\n","                target = (target,)\n","                loss_inputs += target\n","\n","            loss_outputs = loss_fn(*loss_inputs)\n","            loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n","            val_loss += loss.item()\n","            \n","            _, predicted = outputs[0].max(1)\n","            y_probs += outputs[0].cpu()\n","            y_preds += predicted.cpu()\n","            y_targets += target[0].cpu()\n","                \n","    val_loss /= len(val_loader)\n","    return val_loss, y_targets, y_preds, y_probs"]},{"cell_type":"markdown","metadata":{},"source":["---\n","# Simple Training:\n","### Prepare Dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["root = \"path/to/dataset/\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T02:25:55.673034Z","iopub.status.busy":"2024-03-21T02:25:55.672355Z","iopub.status.idle":"2024-03-21T02:25:55.700830Z","shell.execute_reply":"2024-03-21T02:25:55.699796Z","shell.execute_reply.started":"2024-03-21T02:25:55.673006Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 32\n","\n","def toTensor(image):\n","    return torch.tensor(image, dtype=torch.float32)\n","\n","transform=transforms.Compose([\n","    aplicar_transformada_haar_merged, #aplicar_transformada_fourier,\n","    toTensor,\n","])\n","\n","CLASSES = os.listdir(root)\n","anns = [(os.path.join(root, classe, img), classe) for classe in CLASSES for img in os.listdir(os.path.join(root, classe))]\n","X = [ann[0] for ann in anns]\n","y = [ann[1] for ann in anns]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n","\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","\n","y_train = le.fit_transform(y_train)\n","y_test = le.transform(y_test)\n","y_val = le.transform(y_val)\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n","train_dataset = BlurDataset(X_train, y_train, True, transform)\n","test_dataset = BlurDataset(X_test, y_test, False, transform)\n","val_dataset = BlurDataset(X_val, y_val, False, transform)\n","print(len(X_train), len(X_test), len(X_val), le.classes_)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, **kwargs)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T02:25:58.805943Z","iopub.status.busy":"2024-03-21T02:25:58.805593Z","iopub.status.idle":"2024-03-21T02:25:59.364468Z","shell.execute_reply":"2024-03-21T02:25:59.363435Z","shell.execute_reply.started":"2024-03-21T02:25:58.805916Z"},"trusted":true},"outputs":[],"source":["# Show sample:\n","import random\n","r1 = random.randint(0, train_dataset.__len__())\n","img, label = train_dataset.__getitem__(r1)\n","print(img.shape, label)\n","\n","plt.subplot(121), plt.imshow(img.squeeze(), cmap='gray')\n","plt.title('Input'), plt.xticks([]), plt.yticks([])"]},{"cell_type":"markdown","metadata":{},"source":["### Train Model:"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T03:35:55.236971Z","iopub.status.busy":"2024-03-16T03:35:55.236623Z","iopub.status.idle":"2024-03-16T03:35:55.241722Z","shell.execute_reply":"2024-03-16T03:35:55.240618Z","shell.execute_reply.started":"2024-03-16T03:35:55.236943Z"},"trusted":true},"outputs":[],"source":["EPOCHS = 30\n","LR = 1e-3\n","LOSS_FN = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train:\n","model = CNN()\n","if cuda:\n","    model.cuda()\n","\n","optimizer = optim.Adam(model.parameters(), lr=LR)\n","scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n","history = fit(train_loader, val_loader, model, LOSS_FN, optimizer, scheduler, EPOCHS, cuda, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save Model:\n","save_path = f'./model.pth'\n","torch.save(model.state_dict(), save_path)"]},{"cell_type":"markdown","metadata":{},"source":["### Test Model:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T04:12:04.768684Z","iopub.status.busy":"2024-03-16T04:12:04.767842Z","iopub.status.idle":"2024-03-16T04:12:11.036398Z","shell.execute_reply":"2024-03-16T04:12:11.035235Z","shell.execute_reply.started":"2024-03-16T04:12:04.768651Z"},"trusted":true},"outputs":[],"source":["test_loss, y_targets, y_preds, y_probs = test_epoch(test_loader, model, LOSS_FN, cuda)\n","test_acc, test_prec, test_rec, test_auc = get_metrics(y_targets, y_preds, y_probs)\n","message = 'Test set - acc: {:.4f} | precision: {:.4f} | recall: {:.4f} | AUC: {:.4f}'.format(\n","    test_acc, test_prec, test_rec, test_auc)\n","print(message)"]},{"cell_type":"markdown","metadata":{},"source":["---\n","# Cross-Validation:"]},{"cell_type":"markdown","metadata":{},"source":["### Prepare Dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["root = \"path/to/dataset/\""]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T20:53:03.414273Z","iopub.status.busy":"2024-03-21T20:53:03.413353Z","iopub.status.idle":"2024-03-21T20:53:03.436879Z","shell.execute_reply":"2024-03-21T20:53:03.436021Z","shell.execute_reply.started":"2024-03-21T20:53:03.414239Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import KFold\n","from sklearn.preprocessing import LabelEncoder\n","\n","def toTensor(image):\n","    return torch.tensor(image, dtype=torch.float32)\n","\n","transform=transforms.Compose([\n","    aplicar_transformada_fourier, #aplicar_transformada_haar_merged,\n","    toTensor,\n","])\n","\n","root = \"./blur_datasets/mixed_blur_dataset_2/\"\n","CLASSES = os.listdir(root)\n","anns = [(os.path.join(root, classe, img), classe) for classe in CLASSES for img in os.listdir(os.path.join(root, classe))]\n","X = [ann[0] for ann in anns]\n","y = [ann[1] for ann in anns]\n","\n","le = LabelEncoder()\n","y_encoded = le.fit_transform(y)\n","all_data = BlurDataset(X, y_encoded, True, transform)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Show sample:\n","import random\n","r1 = random.randint(0, all_data.__len__())\n","img, label = all_data.__getitem__(r1)\n","print(img.shape, label)\n","\n","plt.subplot(121), plt.imshow(img.squeeze(), cmap='gray')\n","plt.title('Input'), plt.xticks([]), plt.yticks([])"]},{"cell_type":"markdown","metadata":{},"source":["### Start CV process:"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T20:54:18.582992Z","iopub.status.busy":"2024-03-21T20:54:18.582273Z","iopub.status.idle":"2024-03-21T20:54:18.587611Z","shell.execute_reply":"2024-03-21T20:54:18.586718Z","shell.execute_reply.started":"2024-03-21T20:54:18.582960Z"},"trusted":true},"outputs":[],"source":["LR = 1e-3\n","EPOCHS = 30\n","K_FOLDS = 10\n","BATCH_SIZE = 32\n","LOSS_FN = nn.CrossEntropyLoss()\n","results = {}\n","\n","kfold = KFold(n_splits=K_FOLDS, shuffle=True)\n","split_folds = kfold.split(all_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T20:54:21.072632Z","iopub.status.busy":"2024-03-21T20:54:21.072172Z","iopub.status.idle":"2024-03-22T04:09:55.114896Z","shell.execute_reply":"2024-03-22T04:09:55.113761Z","shell.execute_reply.started":"2024-03-21T20:54:21.072602Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","    if hasattr(layer, 'reset_parameters'):\n","        print(f'Reset trainable parameters of layer = {layer}')\n","        layer.reset_parameters()\n","\n","for fold, (train_ids, test_ids) in enumerate(split_folds):\n","    print(f'FOLD {fold+1}')\n","    print('---------------------------------------------------------------------------')\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    train_loader = torch.utils.data.DataLoader(\n","                      all_data, \n","                      batch_size=BATCH_SIZE, sampler=train_subsampler)\n","    test_loader = torch.utils.data.DataLoader(\n","                      all_data,\n","                      batch_size=BATCH_SIZE, sampler=test_subsampler)\n","    \n","    model = CNN()\n","    model.apply(reset_weights)\n","    if cuda:\n","        model.cuda()\n","    optimizer = optim.Adam(model.parameters(), lr=LR)\n","    scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n","    history = fit(train_loader, None, model, LOSS_FN, optimizer, scheduler, EPOCHS, cuda, 0)\n","    \n","    # print('Training process has finished. Saving trained model.')\n","    # save_path = f'./blur-mix-fourier-fold-{fold}.pth'\n","    # torch.save(model.state_dict(), save_path)\n","    # Load models:\n","    # model = CNN().to(\"cuda\")\n","    # model.load_state_dict(torch.load(f'./blur-coco-model-fold-{fold}.pth', map_location=torch.device('cuda')))\n","    \n","    print('Starting testing...')\n","    test_loss, y_targets, y_preds, y_probs = test_epoch(test_loader, model, LOSS_FN, cuda)\n","    test_acc, test_prec, test_rec, test_auc = get_metrics(y_targets, y_preds, y_probs)\n","    y_probs = np.array(y_probs)\n","    y_onehot_test = np.array([[int(tg.item()==0), int(tg.item()==1), int(tg.item()==2)] for tg in y_targets])\n","    results[fold] = {\n","        \"acc\": test_acc,\n","        \"prec\": test_prec,\n","        \"rec\": test_rec,\n","        \"auc\": test_auc,\n","        \"probs\": y_probs,\n","        \"y_onehot\": y_onehot_test,\n","        \"history\": history,\n","    }\n","    \n","    message = 'Test set - acc: {:.4f} | precision: {:.4f} | recall: {:.4f} | auc: {:.4f}'.format(\n","        test_acc, test_prec, test_rec, test_auc)\n","    print(message)\n","    print('---------------------------------------------------------------------------')    "]},{"cell_type":"markdown","metadata":{},"source":["### Show Results:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-16T18:03:59.820501Z","iopub.status.busy":"2024-03-16T18:03:59.820120Z","iopub.status.idle":"2024-03-16T18:04:00.284300Z","shell.execute_reply":"2024-03-16T18:04:00.283261Z","shell.execute_reply.started":"2024-03-16T18:03:59.820464Z"},"trusted":true},"outputs":[],"source":["# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {K_FOLDS} FOLDS')\n","print('-------------------------------------------')\n","\n","fig, ax = plt.subplots(figsize=(6, 6))\n","\n","avg_acc = 0.0\n","avg_prec = 0.0\n","avg_rec = 0.0\n","avg_auc = 0.0\n","\n","colors = [\"darkgrey\", \"red\", \"peru\", \"darkorange\", \"gold\",\n","          \"yellowgreen\", \"turquoise\", \"blue\", \"violet\", \"hotpink\"]\n","\n","for fold in range(K_FOLDS):\n","    message = 'Test set - acc: {:.4f} | precision: {:.4f} | recall: {:.4f} | auc: {:.4f}'.format(\n","        results[fold][\"acc\"], results[fold][\"prec\"], results[fold][\"rec\"], results[fold][\"auc\"])\n","    print(f'Fold {fold+1}-', message)\n","    avg_acc += results[fold][\"acc\"]\n","    avg_prec += results[fold][\"prec\"]\n","    avg_rec += results[fold][\"rec\"]\n","    avg_auc += results[fold][\"auc\"]\n","    \n","    RocCurveDisplay.from_predictions(\n","        results[fold][\"y_onehot\"].ravel(),\n","        results[fold][\"probs\"].ravel(),\n","        name=f'micro-average OvR: Fold-{fold+1}',\n","        color=colors[fold],\n","        ax=ax\n","    )\n","    \n","print('\\n\\nAverage Acc: {:.2f} %'.format(100*avg_acc/len(results.items())))\n","print('Average Prec: {:.2f} %'.format(100*avg_prec/len(results.items())))\n","print('Average Rec: {:.2f} %'.format(100*avg_rec/len(results.items())))\n","print('Average AUC: {:.2f} %'.format(100*avg_auc/len(results.items())))\n","\n","_ = ax.set(\n","    xlabel=\"False Positive Rate\",\n","    ylabel=\"True Positive Rate\",\n","    title=\"Micro-averaged One-vs-Rest\\nReceiver Operating Characteristic\",\n",")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":270005,"sourceId":579020,"sourceType":"datasetVersion"},{"datasetId":4563565,"sourceId":7795196,"sourceType":"datasetVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
